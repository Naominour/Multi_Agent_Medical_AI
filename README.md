# ğŸ¥ Multi Agent Medical AI ğŸ¤–  
ğŸš€ This is an AI-driven **medical question-answering system** integrating **LLaMA 3.1, DeepSeek R1, and Transformer models** to provide **accurate, evidence-based medical responses**.  
It is powered by **3 AI Agents**, **Evidence Retrieval AI Agent**, **Clinical Reasoning AI Agent**, **Uncertainty & Refinement AI Agent**, and features **Human-in-the-Loop (HITL) Review** for ensuring reliability and reducing AI bias.


---
## ğŸ”¥ What's Special About MedAI?
âœ… **Fine-Tuned LLaMA & DeepSeek on 20,000+ Medical Data Points** ğŸ“Š  
   - Trained on a **large-scale medical dataset** for **domain-specific accuracy**.  
   - Ensures **high-quality, expert-verified medical answers**.  

ğŸ“Œ **GitHub Link to Fine-Tuned Models:**  
ğŸ”— **[Fine-Tuned LLaMA 3.1 Model](https://github.com/Naominour/Fine_Tuning_LLaMA_Model)**  
ğŸ”— **[Fine-Tuned DeepSeek R1 Model](https://github.com/Naominour/Fine-tuning-DeepSeek-R1)**  

---

## ğŸ¤– AI Agent Architecture (Human-in-the-Loop)
MedAI's response pipeline includes **3 AI agents** working together, with optional **human expert review**.

### ğŸ”¹ **1ï¸âƒ£ Evidence Retrieval Agent (AI)**
   - **Fetches medical literature** from **PubMed** and **other sources**.
   - Ensures responses are **evidence-based**.

### ğŸ”¹ **2ï¸âƒ£ Clinical Reasoning Agent (AI)**
   - **Uses fine-tuned LLaMA 3** to generate a **structured medical response**.
   - Applies **chain-of-thought (CoT) reasoning**.

### ğŸ”¹ **3ï¸âƒ£ Uncertainty & Refinement Agent (AI)**
   - **Fine-Tuned DeepSeek model refines** AI-generated responses.
   - **Bias detection & uncertainty scoring** (Monte Carlo Dropout, Perplexity).

### ğŸ”¹ **4ï¸âƒ£ Human Expert Review (Optional)**
   - **Doctors or experts** review and refine responses.
   - Ensures **AI reliability** in **critical medical queries**.

> ğŸ’¡ **Human-in-the-Loop (HITL) ensures AI-assisted, expert-reviewed responses!**

---

## ğŸ“Œ Features
âœ… **Fine-Tuned LLaMA & DeepSeek on 20,000+ Medical Data**  
âœ… **AI-Powered Medical Answer Generation** (LLaMA 3 + DeepSeek)  
âœ… **Evidence-Based Retrieval** (PubMed API)  
âœ… **Bias & Uncertainty Detection** (Lexical & Sentiment Bias, Perplexity)  
âœ… **Monte Carlo Dropout (MC-D) for Stability**  
âœ… **Human Expert Review (HITL) for Refinement**  
âœ… **Memory-Efficient Execution** (Prevents GPU OOM errors)  

---

## âš¡ Installation
### ğŸ”¹ 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/Naominour/Multi_Agent_Medical_AI.git
cd Multi_Agent_Medical_AI
```

### ğŸ”¹ 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### ğŸ”¹ 3ï¸âƒ£ Download Fine-Tuned LLaMA & DeepSeek Models 
Download the fine-tuned models from:  
ğŸ”— **[Fine-Tuned Model Repository](https://github.com/your-finetuned-models-repo)**

Then, place them in:
```bash
data/llama/
data/deepseek/
```
ğŸ“Œ **Note: Use Hugging Face's transformers library to download models automatically.**

# ğŸš€ Running the Project

Once dependencies and models are set up, run:

```bash
python main.py
```

## âœ… Example Input:
```bash
Enter your medical question: What are the early signs of Alzheimer's disease?
Is a human expert available for review? (y/n): y
```
## âœ… Example Output:
```bash
{
  "User Question": "What are the early signs of Alzheimer's disease?",
  "Final Response": "Early signs of Alzheimer's include memory loss, confusion, difficulty in problem-solving, and changes in mood or personality."
}
```
## âœ… Response saved in: data/output/result.json

---

## ğŸ’¡ How It Works
1ï¸âƒ£ **Retrieve Evidence (AI) ğŸ›ï¸**  
   - **PubMed API fetches** medical literature.  
   - Provides **peer-reviewed references** for credibility.  

2ï¸âƒ£ **Generate Response (AI) ğŸ¤–**  
   - **Fine-Tuned LLaMA 3 generates structured clinical answers**.  
   - Applies **Chain-of-Thought (CoT) reasoning** for logical step-by-step answers.  

3ï¸âƒ£ **Compute Relevance & Uncertainty (AI) ğŸ“Š**  
   - **Sentence Transformer checks response relevance**.  
   - **Monte Carlo Dropout (MC-D) ensures stability**.  
   - **OPT-1.3B Model calculates perplexity (uncertainty score)**.  

4ï¸âƒ£ **Refine with DeepSeek (AI) ğŸ› ï¸**  
   - **Fine-Tuned DeepSeek refines responses for clarity & accuracy**.  
   - **Now enhanced with Chain-of-Thought (CoT) refinement** to ensure logical reasoning.  

5ï¸âƒ£ **Human Expert Review (Optional) ğŸ©º**  
   - **Doctors or professionals review AI-generated answers**.  
   - Ensures **safe, expert-verified responses**.
     
---

## ğŸ“Š Performance Metrics

   âœ”ï¸ **Relevance Score (Cosine Similarity)**
   âœ”ï¸ **Perplexity Score (Uncertainty)**
   âœ”ï¸ **Bias Detection (Lexical & Sentiment Bias)**
   âœ”ï¸ **Monte Carlo Dropout Stability**

---

## ğŸ› ï¸ Configuration

Modify main.py to customize **API keys, models, or parameters**
```bash
retrieval_agent = EvidenceRetrievalAgent(api_key="YOUR_PUBMED_API_KEY")
llama = LlamaModel(ckpt_dir="data/llama/", tokenizer_path="data/llama/tokenizer.model")
deepseek = DeepSeekModel(model_path="data/deepseek/merged_model")
```

---

## ğŸ“Œ Example Use Cases

  âœ… **Medical Question Answering â€“ Get accurate, evidence-based medical responses.**
  âœ… **Clinical Decision Support â€“ Doctors & researchers can validate AI-generated insights.**
  âœ… **Human-AI Collaboration â€“ HITL ensures safer AI-assisted medicine.**

---

## ğŸ“œ License

This project is licensed under the **MIT License.**
